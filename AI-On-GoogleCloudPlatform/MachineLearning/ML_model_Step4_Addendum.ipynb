{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQ-myWyg4tC5"
   },
   "source": [
    "<h1>E-commerce via Computer Vision</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WARtiPJ7_sAl"
   },
   "source": [
    "## Machine Learning: Addendum to 3rd Level of Fine Tuning (4th Step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At deployment time (March 2019)  the below-noted changes were made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps 1 through 4 were done exactly as show in the preceding notebooks, with two notable exceptions.   First, all notebooks were run with a Python 2 (2.7) kernel, rather than Python 3 (3.6), as doing so integrated well with GCP's native MLE query/prediction request service, discovery.   Second, rather than using VGG16's bottleneck layers as one object/1st layer of a concise model,  VGG16's model was simply reiterated in its full form and then used for bottlenecks and later sequential fine tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the ultimate fine tuning was run as before, deployment was effectuated as below (with these additional cells in that same Step4 Notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the Keras model, save its session, make it a GraphDef, & elim. unnecessary indexing of 0 (only 1 img/MLE online predict)\n",
    "K.set_learning_phase(0)  # testing/frozen\n",
    "sess = K.get_session()\n",
    "# Make GraphDef of Train Model\n",
    "graph_train = sess.graph\n",
    "graph_train_def = graph_util.convert_variables_to_constants(sess, graph_train.as_graph_def(), [my_model.output.name.replace(':0','')])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INFO:tensorflow:Froze 30 variables.\n",
    "Converted 30 variables to const ops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a 2nd graph to inject a bitstring-to-input_tensor pipeline/input pre-processor\n",
    "with tf.Graph().as_default() as graph_input:\n",
    "  # Define a function: map each bitstring ('input_bytes') to an RGB image ('input_tensor')\n",
    "  # https://stackoverflow.com/questions/55008988/tensorflow-serving\n",
    "  # -for-images-as-base64-encoded-strings-on-cloud-ml-engine\n",
    "  def bytes_to_image(input_b64):\n",
    "    image = tf.image.decode_image(input_b64, channels=3) # image in RGB\n",
    "    image.set_shape([None, None, None])\n",
    "    image = tf.image.resize_images(image, [224, 224])\n",
    "    image = tf.divide(image, 255) # [0,1] scale for each pixel vector element\n",
    "    image.set_shape([224, 224, 3])\n",
    "    image = tf.reverse(image, axis=[2]) # RGB_2_BGR\n",
    "    \n",
    "    return image\n",
    "    \n",
    "  input_bytes = tf.placeholder(tf.string, shape=None, name=\"input_bytes\")\n",
    "  input_tensor = tf.map_fn(bytes_to_image, input_bytes, \n",
    "       back_prop=False, dtype=tf.float32)\n",
    "  output = tf.identity(input_tensor, name='input_image')\n",
    "  # Convert graph_input to a GraphDef\n",
    "  graph_input_def = graph_input.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the output directory, where the combined graph will be persisted\n",
    "export_path = os.path.join(\n",
    "      tf.compat.as_bytes(export_path_base),\n",
    "      tf.compat.as_bytes(str(model_version_no)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build a 3rd graph, combining the prior 2, and then persist the combined graph as a SavedModel\n",
    "with tf.Graph().as_default() as graph_combined:\n",
    "    # https://github.com/hayatoy/cloudmlmagic/\n",
    "    # blob/master/examples/Keras_Fine_Tuning.ipynb\n",
    "    x = tf.placeholder(tf.string, name=\"input_b64\")\n",
    "\n",
    "    img, = tf.import_graph_def(graph_input_def,\n",
    "                              input_map={'input_bytes:0': x},\n",
    "                              return_elements=[\"input_image:0\"])\n",
    "\n",
    "    preds, = tf.import_graph_def(graph_train_def,\n",
    "                                input_map={my_model.input.name: img},\n",
    "                                return_elements=[my_model.output.name])\n",
    "                                           \n",
    "    # Now persist the final, combined graph to export_path\n",
    "    with tf.Session() as sess2: \n",
    "        # inputs' alias suffix = '_bytes' for Cloud MLE\n",
    "        inputs = {\"image_bytes\": tf.saved_model.utils.build_tensor_info(x)} \n",
    "        outputs = {\"predictions\":\n",
    "           tf.saved_model.utils.build_tensor_info(preds)}\n",
    "        signature = tf.saved_model.signature_def_utils.build_signature_def(\n",
    "           inputs=inputs,\n",
    "           outputs=outputs,\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME       \n",
    "        )\n",
    "\n",
    "        # save as SavedModel\n",
    "        builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "        builder.add_meta_graph_and_variables(sess2,\n",
    "            [tf.saved_model.tag_constants.SERVING],\n",
    "                  signature_def_map={'serving_default': signature})\n",
    "        builder.save()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "INFO:tensorflow:No assets to save.\n",
    "INFO:tensorflow:No assets to write.\n",
    "INFO:tensorflow:SavedModel written to: ./wrenches_models/10/saved_model.pb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "demandforecast.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
